<source>
  type forward
  port 24224
  bind 0.0.0.0
</source>

<match *.**>
  # 複数の出力先に分岐する
  type copy

  <store>
    type stdout
  </store>

  <store>
    # fluent-plugin-s3 が必要
    type s3

    # docker run時に-eで環境変数を指定する
    aws_key_id #{ENV['AWS_ACCESS_KEY_ID']}
    aws_sec_key #{ENV['AWS_SECRET_ACCESS_KEY']}

    s3_bucket test.h-kento.jp
    s3_region ap-northeast-1

    # デフォルトではgz圧縮される
    # indexはtime_sliceが被ったときの連番
    s3_object_key_format %{path}%{time_slice}_%{index}_%{hostname}.%{file_extension}
    
    # バケット内のパス
    path logs/

    # Dockerfileでfluentdのユーザーに書き込み権限を設定したパスを設定
    # s3.20161012%2F20161012-15.ea9af2da9eb53eacb.log の形でバッファが出力される
    buffer_path /fluentd/log/s3

    # テストのためごく短く設定している
    flush_interval 1s
    time_slice_format %Y%m%d/%Y%m%d-%H
  </store>
</match>
